{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "#import mysql.connector\n",
    "from pandas.io import sql\n",
    "import sqlalchemy\n",
    "import re\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "#from baseball_scraper import playerid_lookup\n",
    "from pybaseball import playerid_lookup\n",
    "from urllib.parse import quote_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170705\n",
      "deleted double header rows\n"
     ]
    }
   ],
   "source": [
    "# %run elon_functions.py\n",
    "\n",
    "# Give the location of the file \n",
    "loc = (\"data/GameLogs_1419.csv\") \n",
    "# To open Workbook \n",
    "df = pd.read_csv(loc)\n",
    "\n",
    "\n",
    "print(len(df))\n",
    "to_delete = []\n",
    "#delete the double headers. Confuses the model.\n",
    "for row, col in df.iterrows():\n",
    "    r = df.iloc[row]\n",
    "    if (len(r[\"Date\"]) >10):\n",
    "        to_delete.append(row)\n",
    "df = df.drop(to_delete, axis = 0)      \n",
    "print(\"deleted double header rows\")\n",
    "df.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = [x[0:10] for x in df[\"Date\"]]\n",
    "df['Date'] = df['Date'].apply(lambda x: dt.datetime.strptime(x,'%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering player lookup table. This may take a moment.\n"
     ]
    }
   ],
   "source": [
    "def make_player_id_dict(df):\n",
    "    player_names = list(df[\"Player\"].unique())\n",
    "    name_id_dict = {}\n",
    "    for x in player_names:\n",
    "        first_name = re.findall('(.*) ', x)[0]\n",
    "        last_name = re.findall('.* (.*)\\\\\\\\', x)[0]\n",
    "        \n",
    "        if (first_name[1] =='.'):\n",
    "            first_name = first_name[:2] + ' ' + first_name[2:]\n",
    "        lookup_id = 0\n",
    "        try:\n",
    "            lookup_id_df = playerid_lookup(last_name, first_name)\n",
    "            if(len(lookup_id_df) > 1):\n",
    "                lookup_id_df = lookup_id_df.dropna()\n",
    "                if(len(lookup_id_df) >1):\n",
    "                    lookup_id = -1 # player has two people with the same name\n",
    "                else:\n",
    "                    lookup_id = lookup_id_df['key_mlbam'].values[0]\n",
    "            else:\n",
    "                lookup_id = lookup_id_df['key_mlbam'].values[0]\n",
    "        except:\n",
    "            lookup_id = -1\n",
    "        if (lookup_id != -1):\n",
    "            name_id_dict[(first_name, last_name)] = lookup_id\n",
    "    \n",
    "    return name_id_dict\n",
    "\n",
    "my_dict = make_player_id_dict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_next_game_details(df2):\n",
    "    #determine if the player gets a hit the next game\n",
    "    df_huge = pd.DataFrame()\n",
    "    player_names= list(df2[\"Name\"].unique())\n",
    "    for name in player_names:\n",
    "        df_player = df2[df2[\"Name\"] == name]\n",
    "        df_p = df_player.sort_values(by = [\"fixed_date\"])\n",
    "        df_p[\"next_game_BA\"] = df_p[\"BA\"].shift(-1)\n",
    "        df_p[\"next_game_Name\"] = df_p[\"Name\"].shift(-1)\n",
    "        df_p[\"next_game_Date\"] = df_p[\"fixed_date\"].shift(-1)\n",
    "        df_p[\"key\"] = df_p[\"key\"].shift(-1)\n",
    "        df_huge = pd.concat([df_huge, df_p], axis = 0)\n",
    "    return df_huge    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dumping the contents of my_dict into a picklized file\n",
    "import pickle\n",
    "with open('data/mydict.pickle','wb') as handle:\n",
    "    pickle.dump(my_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Brendan', 'McKay')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(my_dict)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Once the scraping is complete, we then combine our two dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loc = (\"data/aggregates.csv\") \n",
    "loc = (\"data/aggregates2.csv\")\n",
    "# To open Workbook \n",
    "df2 = pd.read_csv(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "for i,x in enumerate(df2[\"Game_date\"]):\n",
    "    try:\n",
    "        j = dt.datetime.strptime(x,'%m/%d/%Y')\n",
    "    except:\n",
    "        try:\n",
    "            #j = dt.datetime.strptime(x,'%Y-%m-%d %H:%M:%S')\n",
    "            j = dt.datetime.strptime(x,'%Y-%m-%d')\n",
    "        except:\n",
    "            try:\n",
    "                j = dt.datetime.strptime(x,'%m/%d/%Y %H:%M')\n",
    "            except:\n",
    "                print(i,x, \"didn't pass third case\")\n",
    "    dates.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(dates) == len(df2))\n",
    "df2[\"fixed_date\"] = [str(k)[:10] for k in dates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a hash key with the player name and date information in order to merge df and df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_date = []\n",
    "#make the keys for the game log df\n",
    "for row,col in df.iterrows():\n",
    "    row = df.iloc[row]\n",
    "    player_name = row[\"Player\"]\n",
    "    first_name = re.findall('(.*) ', player_name)[0]\n",
    "    #if the name has a '.' in it like \"A.J.\"\n",
    "    if (first_name[1] =='.'):\n",
    "        first_name = first_name[:2] + ' ' + first_name[2:]\n",
    "    last_name = re.findall('.* (.*)\\\\\\\\', player_name)[0]\n",
    "    name = first_name + ' ' + last_name\n",
    "    date = str(row[\"Date\"])[:10]\n",
    "    name_date.append(hash(name+date))\n",
    "df[\"key\"] = name_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_date = []\n",
    "#make the key for the aggregate stats df\n",
    "for row,col in df2.iterrows():\n",
    "    row = df2.iloc[row]\n",
    "    player_name = row[\"Name\"]\n",
    "    date = row[\"fixed_date\"]\n",
    "#     print(player_name+date)\n",
    "    name_date.append(hash(player_name+date))\n",
    "#create a key that will enable us to merge dataframes. \n",
    "df2[\"key\"] = name_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = append_next_game_details(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dic = {}\n",
    "# duplicates = []\n",
    "# for j in df[\"key\"]:\n",
    "#     if (j in dic):\n",
    "#         duplicates.append(j)\n",
    "#     else:\n",
    "#         dic[j] = 1\n",
    "# print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joins are only possible if the keys and their datatypes are the same\n",
    "df2[\"key\"] =df2[\"key\"].astype(float)\n",
    "df[\"key\"] = df[\"key\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_df = df2.join(df.set_index('key'), on='key', rsuffix='agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BA</th>\n",
       "      <th>BABIP</th>\n",
       "      <th>BIP</th>\n",
       "      <th>Game_date</th>\n",
       "      <th>Games_played_to_date</th>\n",
       "      <th>ISO</th>\n",
       "      <th>LA_avg</th>\n",
       "      <th>LA_median</th>\n",
       "      <th>Name</th>\n",
       "      <th>OBP</th>\n",
       "      <th>...</th>\n",
       "      <th>X3B</th>\n",
       "      <th>HR</th>\n",
       "      <th>RBI</th>\n",
       "      <th>BB</th>\n",
       "      <th>SO</th>\n",
       "      <th>WPA</th>\n",
       "      <th>RE24</th>\n",
       "      <th>aLI</th>\n",
       "      <th>BOP</th>\n",
       "      <th>Pos.Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Travis d'Arnaud</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.425</td>\n",
       "      <td>0.870</td>\n",
       "      <td>7.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>2014-04-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Travis d'Arnaud</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.638</td>\n",
       "      <td>7.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>2014-04-08</td>\n",
       "      <td>6</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Travis d'Arnaud</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.453</td>\n",
       "      <td>1.220</td>\n",
       "      <td>7.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>2014-04-09</td>\n",
       "      <td>7</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Travis d'Arnaud</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-1.535</td>\n",
       "      <td>1.913</td>\n",
       "      <td>7.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>2014-04-14</td>\n",
       "      <td>11</td>\n",
       "      <td>0.100996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Travis d'Arnaud</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.180</td>\n",
       "      <td>7.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33898</th>\n",
       "      <td>0.270522</td>\n",
       "      <td>0.295405</td>\n",
       "      <td>0.860037</td>\n",
       "      <td>2014-09-17</td>\n",
       "      <td>136</td>\n",
       "      <td>0.121743</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ben Zobrist</td>\n",
       "      <td>0.351525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>-0.846</td>\n",
       "      <td>1.153</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33899</th>\n",
       "      <td>0.270370</td>\n",
       "      <td>0.295011</td>\n",
       "      <td>0.861060</td>\n",
       "      <td>2014-09-19</td>\n",
       "      <td>137</td>\n",
       "      <td>0.120854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ben Zobrist</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060</td>\n",
       "      <td>1.147</td>\n",
       "      <td>0.620</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33902</th>\n",
       "      <td>0.275046</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.863309</td>\n",
       "      <td>2014-09-23</td>\n",
       "      <td>140</td>\n",
       "      <td>0.120638</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ben Zobrist</td>\n",
       "      <td>0.354788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.432</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33903</th>\n",
       "      <td>0.276173</td>\n",
       "      <td>0.301053</td>\n",
       "      <td>0.864528</td>\n",
       "      <td>2014-09-24</td>\n",
       "      <td>141</td>\n",
       "      <td>0.121331</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ben Zobrist</td>\n",
       "      <td>0.355140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>0.820</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33904</th>\n",
       "      <td>0.275986</td>\n",
       "      <td>0.300626</td>\n",
       "      <td>0.865487</td>\n",
       "      <td>2014-09-25</td>\n",
       "      <td>142</td>\n",
       "      <td>0.120475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ben Zobrist</td>\n",
       "      <td>0.354489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.779</td>\n",
       "      <td>1.233</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19498 rows Ã— 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             BA     BABIP       BIP   Game_date  Games_played_to_date   \n",
       "1      0.000000  0.000000  0.500000  2014-04-02                     2  \\\n",
       "4      0.000000  0.000000  0.600000  2014-04-06                     5   \n",
       "5      0.105263  0.153846  0.684211  2014-04-08                     6   \n",
       "6      0.130435  0.176471  0.739130  2014-04-09                     7   \n",
       "10     0.162162  0.178571  0.763158  2014-04-14                    11   \n",
       "...         ...       ...       ...         ...                   ...   \n",
       "33898  0.270522  0.295405  0.860037  2014-09-17                   136   \n",
       "33899  0.270370  0.295011  0.861060  2014-09-19                   137   \n",
       "33902  0.275046  0.300000  0.863309  2014-09-23                   140   \n",
       "33903  0.276173  0.301053  0.864528  2014-09-24                   141   \n",
       "33904  0.275986  0.300626  0.865487  2014-09-25                   142   \n",
       "\n",
       "            ISO  LA_avg  LA_median             Name       OBP  ...  X3B   HR   \n",
       "1      0.000000     NaN        NaN  Travis d'Arnaud  0.142857  ...  0.0  0.0  \\\n",
       "4      0.000000     NaN        NaN  Travis d'Arnaud  0.117647  ...  0.0  0.0   \n",
       "5      0.052632     NaN        NaN  Travis d'Arnaud  0.190476  ...  0.0  0.0   \n",
       "6      0.043478     NaN        NaN  Travis d'Arnaud  0.200000  ...  0.0  0.0   \n",
       "10     0.100996     NaN        NaN  Travis d'Arnaud  0.219512  ...  0.0  0.0   \n",
       "...         ...     ...        ...              ...       ...  ...  ...  ...   \n",
       "33898  0.121743     NaN        NaN      Ben Zobrist  0.351525  ...  0.0  0.0   \n",
       "33899  0.120854     NaN        NaN      Ben Zobrist  0.350877  ...  0.0  0.0   \n",
       "33902  0.120638     NaN        NaN      Ben Zobrist  0.354788  ...  0.0  0.0   \n",
       "33903  0.121331     NaN        NaN      Ben Zobrist  0.355140  ...  0.0  0.0   \n",
       "33904  0.120475     NaN        NaN      Ben Zobrist  0.354489  ...  0.0  0.0   \n",
       "\n",
       "       RBI   BB   SO    WPA   RE24    aLI  BOP  Pos.Summary  \n",
       "1      0.0  1.0  2.0 -0.037 -0.425  0.870  7.0            C  \n",
       "4      0.0  0.0  0.0  0.066  0.277  0.638  7.0            C  \n",
       "5      1.0  0.0  0.0  0.028  0.453  1.220  7.0            C  \n",
       "6      0.0  0.0  0.0 -0.186 -1.535  1.913  7.0            C  \n",
       "10     0.0  2.0  1.0 -0.005  0.259  0.180  7.0            C  \n",
       "...    ...  ...  ...    ...    ...    ...  ...          ...  \n",
       "33898  0.0  0.0  0.0 -0.120 -0.846  1.153  1.0           LF  \n",
       "33899  1.0  1.0  0.0  0.060  1.147  0.620  1.0           LF  \n",
       "33902  1.0  0.0  0.0  0.004  0.773  0.432  1.0           DH  \n",
       "33903  1.0  0.0  0.0  0.033 -0.079  0.820  1.0           SS  \n",
       "33904  0.0  0.0  1.0 -0.124 -0.779  1.233  1.0           2B  \n",
       "\n",
       "[19498 rows x 113 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mega_df[mega_df[\"Pos.Summary\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_cols = ['160421_183314_percentage_hits', '160421_204540_percentage_hits',\n",
    "       '160421_194503_percentage_hits', '160421_182611_percentage_hits',\n",
    "       '160421_195036_percentage_hits', '160421_191133_percentage_hits',\n",
    "       '160421_200605_percentage_hits', '160421_202513_percentage_hits',\n",
    "       '160421_193312_percentage_hits', '160421_195422_percentage_hits',\n",
    "       '160421_182835_percentage_hits','160421_182316_percentage_hits', '160421_185447_percentage_hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['160421_183314_percentage_hits', '160421_204540_percentage_hits', '160421_194503_percentage_hits', '160421_182611_percentage_hits', '160421_195036_percentage_hits', '160421_191133_percentage_hits', '160421_200605_percentage_hits', '160421_193312_percentage_hits', '160421_195422_percentage_hits', '160421_182835_percentage_hits', '160421_182316_percentage_hits', '160421_185447_percentage_hits'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mega_df \u001b[39m=\u001b[39m mega_df\u001b[39m.\u001b[39;49mdrop(columns \u001b[39m=\u001b[39;49m [\u001b[39m\"\u001b[39;49m\u001b[39mUnnamed: 0\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mGame_date\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mfixed_date\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m+\u001b[39;49m bad_cols)\n",
      "File \u001b[0;32m~/.venv/mlb_hit_predictor/lib/python3.9/site-packages/pandas/core/frame.py:5268\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[1;32m   5121\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   5122\u001b[0m     labels: IndexLabel \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5129\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   5130\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5131\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5132\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5133\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5266\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5267\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5268\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m   5269\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   5270\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   5271\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   5272\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   5273\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   5274\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   5275\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   5276\u001b[0m     )\n",
      "File \u001b[0;32m~/.venv/mlb_hit_predictor/lib/python3.9/site-packages/pandas/core/generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4547\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   4548\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4549\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4551\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   4552\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/.venv/mlb_hit_predictor/lib/python3.9/site-packages/pandas/core/generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4589\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4590\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4591\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4592\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4594\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4595\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.venv/mlb_hit_predictor/lib/python3.9/site-packages/pandas/core/indexes/base.py:6696\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6694\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m   6695\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 6696\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6697\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m   6698\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['160421_183314_percentage_hits', '160421_204540_percentage_hits', '160421_194503_percentage_hits', '160421_182611_percentage_hits', '160421_195036_percentage_hits', '160421_191133_percentage_hits', '160421_200605_percentage_hits', '160421_193312_percentage_hits', '160421_195422_percentage_hits', '160421_182835_percentage_hits', '160421_182316_percentage_hits', '160421_185447_percentage_hits'] not found in axis\""
     ]
    }
   ],
   "source": [
    "mega_df = mega_df.drop(columns = [\"Unnamed: 0\", \"Game_date\",\"fixed_date\"] + bad_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BA', 'BABIP', 'BIP', 'Game_date', 'Games_played_to_date', 'ISO',\n",
       "       'LA_avg', 'LA_median', 'Name', 'OBP',\n",
       "       ...\n",
       "       'X3B', 'HR', 'RBI', 'BB', 'SO', 'WPA', 'RE24', 'aLI', 'BOP',\n",
       "       'Pos.Summary'],\n",
       "      dtype='object', length=113)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mega_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_df = mega_df.reindex(columns=['Name', 'Tm', 'BA', 'BABIP', 'BIP', 'Games_played_to_date', 'ISO', 'LA_avg', 'LA_median','OBP', 'OPS', 'PA', 'SLG', 'Walks', 'mlbam_code',\n",
    "       'FT_percentage_hits', 'pHitsByZone5', 'Weak_lsa_p', 'Topped_lsa_p',\n",
    "       'Under_lsa_p', 'Flare/Burner_lsa_p', 'SolidContact_lsa_p',\n",
    "       'Barrel_lsa_p', 'FF_percentage_hits', 'FC_percentage_hits',\n",
    "       'SI_percentage_hits', 'pHitsByZone2', 'pHitsByZone4', 'pHitsByZone14',\n",
    "       'CH_percentage_hits', 'SL_percentage_hits', 'pHitsByZone1',\n",
    "       'pHitsByZone13', 'pHitsByZone6', 'KC_percentage_hits', 'pHitsByZone7',\n",
    "       'pHitsByZone9', 'CU_percentage_hits', 'FS_percentage_hits',\n",
    "       'pHitsByZone8', 'pHitsByZone12', 'pHitsByZone3', 'pHitsByZone11',\n",
    "       'FO_percentage_hits', 'KN_percentage_hits', 'FA_percentage_hits',\n",
    "       'EP_percentage_hits', 'SC_percentage_hits', 'key', 'next_game_BA',\n",
    "       'next_game_Name', 'next_game_Date', 'next_game_Key', 'Player', 'Date','Opp', 'PAagg', 'AB', 'R', 'H', 'X2B', 'X3B', 'HR', 'RBI', 'BB',\n",
    "       'SO', 'WPA', 'RE24', 'aLI', 'BOP', 'Pos.Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in mega_df.columns:\n",
    "    if (mega_df[col].dtype =='float64'):\n",
    "        mega_df[col] = mega_df[col].round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_df = mega_df[mega_df['BA'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_df= mega_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_df.to_csv('data/aggregate_stats_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made connection\n",
      "0 6000\n",
      "table replace successful\n",
      "6000 6000\n",
      "table append successful\n",
      "12000 6000\n",
      "table append successful\n",
      "18000 6000\n",
      "table append successful\n",
      "24000 6000\n",
      "table append successful\n",
      "30000 4022\n",
      "table append successful\n"
     ]
    }
   ],
   "source": [
    "database_username = 'raguilar'\n",
    "database_password = quote_plus(\"Lb$bYdu^2P%gv%D6cfqNJ7@aAhE&jT7r\")\n",
    "database_ip       = 'localhost'\n",
    "database_name     = 'mlb_dw'\n",
    "\n",
    "database_connection = sqlalchemy.create_engine('postgresql+psycopg2://{0}:{1}@{2}/{3}'.\n",
    "                                               format(database_username, database_password, \n",
    "                                                      database_ip, database_name), pool_timeout = 28800, max_overflow = -1)\n",
    "connection = database_connection.connect()\n",
    "print(\"made connection\")\n",
    "# try:\n",
    "num = 0\n",
    "try:\n",
    "    while(num < (len(mega_df))):\n",
    "        ie = 'append'\n",
    "        if (num == 0):\n",
    "            ie = 'replace'\n",
    "        val = min((len(mega_df) -num), 6000)\n",
    "        print(num,val)\n",
    "        mega_df[num: num+ val].to_sql('aggregate_stats_v1', connection,index=True, if_exists=ie, chunksize = 25000)\n",
    "        print(\"table \"+ ie + \" successful\")\n",
    "        num +=val\n",
    "except:\n",
    "    print(\"error\")\n",
    "    connection.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "my_dict ={}\n",
    "with open('data/mydict.pickle','rb') as handle:\n",
    "    my_dict = pickle.dumps(handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlb_hit_predictor",
   "language": "python",
   "name": "mlb_hit_predictor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
